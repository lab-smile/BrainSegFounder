Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold0_.29436509.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold0_.29436699.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold0_.29437428.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold0_.29439452.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS-T1-Fold0.sh
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold1_.29439973.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS-T1-Fold1.sh
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold2_.29439974.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS-T1-Fold2.sh
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold3_.29439975.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS-T1-Fold3.sh
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS_T1_Fold4_.29439976.out
Apr19_Baseline_M4channels_NoUKBPretrain_BTRATS-T1-Fold4.sh
Feb11_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB10k_BTRATS-Fold0_8GPUs.sh
Feb11_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS-Fold0_8GPUs.sh
Feb11_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS-Fold1_8GPUs.sh
Feb11_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS-Fold2_8GPUs.sh
Feb11_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS-Fold3_8GPUs.sh
Feb11_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS-Fold4_8GPUs.sh
Feb19_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold0_64GPUs.sh
Feb19_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold1_64GPUs.sh
Feb19_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold2_64GPUs.sh
Feb19_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold3_64GPUs.sh
Feb19_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold4_64GPUs.sh
Feb7_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB40k_BTRATS-Fold0_8GPUs.sh
FewShot100%_Baseline_Train_SWINUNETR_Micro4_62M_4channels_NoUKBPretrain_BTRATS.sh
FewShot100%_SWINUNETR_Micro4_62M_4channels_1Stage_UKB40k_BTRATS.sh
FewShot10%_Baseline_Train_SWINUNETR_Micro4_62M_4channels_NoUKBPretrain_BTRATS.sh
FewShot10%_SWINUNETR_Micro4_62M_4channels_1Stage_UKB40k_BTRATS.sh
FewShot20%_Baseline_Train_SWINUNETR_Micro4_62M_4channels_NoUKBPretrain_BTRATS.sh
FewShot20%_SWINUNETR_Micro4_62M_4channels_1Stage_UKB40k_BTRATS.sh
FewShot40%_Baseline_Train_SWINUNETR_Micro4_62M_4channels_NoUKBPretrain_BTRATS.sh
FewShot40%_SWINUNETR_Micro4_62M_4channels_1Stage_UKB40k_BTRATS.sh
FewShot60%_Baseline_Train_SWINUNETR_Micro4_62M_4channels_NoUKBPretrain_BTRATS.sh
FewShot60%_SWINUNETR_Micro4_62M_4channels_1Stage_UKB40k_BTRATS.sh
FewShot80%_Baseline_Train_SWINUNETR_Micro4_62M_4channels_NoUKBPretrain_BTRATS.sh
FewShot80%_SWINUNETR_Micro4_62M_4channels_1Stage_UKB40k_BTRATS.sh
FinetuningSWINUNETR_M4channels_1Stage_UKB40k_BTRATS-Fold0_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_1Stage_UKB40k_BTRATS-Fold1_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_1Stage_UKB40k_BTRATS-Fold2_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_1Stage_UKB40k_BTRATS-Fold3_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_1Stage_UKB40k_BTRATS-Fold4_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_2Stage_UKB40k_BTRATS-Fold0_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_2Stage_UKB40k_BTRATS-Fold1_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_2Stage_UKB40k_BTRATS-Fold2_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_2Stage_UKB40k_BTRATS-Fold3_MultipleGPUs.sh
FinetuningSWINUNETR_M4channels_2Stage_UKB40k_BTRATS-Fold4_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB10k_BTRATS-Fold0_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB10k_BTRATS-Fold1_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB10k_BTRATS-Fold2_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB10k_BTRATS-Fold3_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB10k_BTRATS-Fold4_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB20k_BTRATS-Fold0_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB20k_BTRATS-Fold1_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB20k_BTRATS-Fold2_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB20k_BTRATS-Fold3_MultipleGPUs.sh
FinetuningSWINUNETR_Micro4channels_2Stage_UKB20k_BTRATS-Fold4_MultipleGPUs.sh
FinetuningSWINUNETR_S4channels_2Stage_UKB40k_BTRATS-Fold0_MultipleGPUs.sh
FinetuningSWINUNETR_S4channels_2Stage_UKB40k_BTRATS-Fold1_MultipleGPUs.sh
FinetuningSWINUNETR_S4channels_2Stage_UKB40k_BTRATS-Fold2_MultipleGPUs.sh
FinetuningSWINUNETR_S4channels_2Stage_UKB40k_BTRATS-Fold3_MultipleGPUs_LR1e6.sh
FinetuningSWINUNETR_S4channels_2Stage_UKB40k_BTRATS-Fold3_MultipleGPUs.sh
FinetuningSWINUNETR_S4channels_2Stage_UKB40k_BTRATS-Fold4_MultipleGPUs.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold0_MultipleGPUs_LR1e3.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold0_MultipleGPUs_LR2e4.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold0_MultipleGPUs.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold1_MultipleGPUs.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold2_MultipleGPUs.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold3_MultipleGPUs_LR1e5.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold3_MultipleGPUs.sh
FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold4_MultipleGPUs.sh
Jan15_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold0_8GPUs.sh
Jan15_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold1_8GPUs.sh
Jan15_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold2_8GPUs.sh
Jan15_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold3_8GPUs.sh
Jan15_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold4_8GPUs.sh
Jan16_FinetuningSWINUNETR_Tiny4channels_2Stage_UKB40k_BTRATS-Fold0_8GPUs.sh
Mar242024_FinetuningSWINUNETR_Model_T_64M_4channels_1Stage_UKB40k_BTRATS-Fold0.sh
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS_2GPUs_Fold0_.26818054.out
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS_2GPUs_Fold0_.26818443.out
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS_2GPUs_Fold1_.26818069.out
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS_2GPUs_Fold1_.26818455.out
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS_2GPUs_Fold3_.26818073.out
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS_2GPUs_Fold3_.26818460.out
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T1_UKB20k_BTRATS_2GPUs_Fold4_.26818465.out
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T2_UKB20k_BTRATS-Fold0.sh
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T2_UKB20k_BTRATS-Fold1.sh
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T2_UKB20k_BTRATS-Fold2.sh
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T2_UKB20k_BTRATS-Fold3.sh
Mar28_FinetuningSWINUNETR_Tiny4channels_2Stage_T2_UKB20k_BTRATS-Fold4.sh
Mar29_FinetuningSWINUNETR_Tiny4channels_2Stage_T2_UKB20k_BTRATS_2GPUs_Fold2_.26915928.out
run_Finetuning.sh
run_FinetuningSWINUNETR_10kSmall4channels_MultipleGPUs.sh
run_FinetuningSWINUNETR_4kBig4channels_MultipleGPUs.sh
run_FinetuningSWINUNETR.sh
run_FinetuningSWINUNETR_Small4channels_MultipleGPUs_Largebachsize.sh
run_FinetuningSWINUNETR_Small4channels_MultipleGPUs.sh
run_FinetuningSWINUNETR_SmallT1T2_MultipleGPUs.sh
run_FinetuningSWINUNETR_SmallT1T2.sh
runs
WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (479) bind mounts
Found total gpus 1
[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:23456 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:23456 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/blue/ruogu.fang/pliu1/BRATS21/main_FinetuningSwinUNETR_4Channels.py", line 300, in <module>
    main()
  File "/blue/ruogu.fang/pliu1/BRATS21/main_FinetuningSwinUNETR_4Channels.py", line 114, in main
    mp.spawn(main_worker, nprocs=args.ngpus_per_node, args=(args,))
  File "/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/blue/ruogu.fang/pliu1/BRATS21/main_FinetuningSwinUNETR_4Channels.py", line 126, in main_worker
    dist.init_process_group(
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 627, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/rendezvous.py", line 201, in _tcp_rendezvous_handler
    store = _create_c10d_store(result.hostname, result.port, rank, world_size, timeout)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/rendezvous.py", line 177, in _create_c10d_store
    return TCPStore(
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:23456 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:23456 (errno: 98 - Address already in use).

